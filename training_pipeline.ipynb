{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b33a205f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Import th√†nh c√¥ng!\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "\n",
    "# Import modules t·ª± t·∫°o\n",
    "from nlp_toolkit import (\n",
    "    DataLoader,\n",
    "    DataCleaner,\n",
    "    TextParser,\n",
    "    BagOfWordsEncoder,\n",
    "    TfidfEncoder,\n",
    "    Word2VecEncoder,\n",
    "    FastTextEncoder,\n",
    "    CharNgramEncoder,\n",
    "    PhoBertEncoder,\n",
    "    convert_json_to_parquet,\n",
    "    save_results_to_pickle\n",
    ")\n",
    "\n",
    "from ml_engine import (\n",
    "    MLTrainer,\n",
    "    PerformanceEvaluator,\n",
    "    ExperimentLogger\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Import th√†nh c√¥ng!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a6c3c62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "B·∫ÆT ƒê·∫¶U X·ª¨ L√ù D·ªÆ LI·ªÜU\n",
      "======================================================================\n",
      "T·ªïng s·ªë comment ban ƒë·∫ßu: 800\n",
      "Sau khi lo·∫°i b·ªè tr√πng l·∫∑p: 758\n",
      "Sau khi l·ªçc ƒë·ªô d√†i: 652\n",
      "ƒêang chu·∫©n h√≥a vƒÉn b·∫£n:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "X·ª≠ l√Ω: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 652/652 [00:00<00:00, 54023.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M·∫´u c√≥ label: 652\n",
      "M·∫´u kh√¥ng c√≥ label: 0\n",
      "\n",
      "‚úÖ Ho√†n th√†nh ti·ªÅn x·ª≠ l√Ω d·ªØ li·ªáu!\n",
      "S·ªë m·∫´u c√≥ label: 652\n",
      "S·ªë m·∫´u kh√¥ng label: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ƒê∆∞·ªùng d·∫´n ƒë·∫øn file d·ªØ li·ªáu\n",
    "DATA_PATH = 'data.parquet'\n",
    "\n",
    "# Kh·ªüi t·∫°o data loader\n",
    "loader = DataLoader(DATA_PATH)\n",
    "\n",
    "# X·ª≠ l√Ω d·ªØ li·ªáu\n",
    "labeled_data, unlabeled_data = loader.process_dataset(sample_limit=None)\n",
    "\n",
    "print(f\"\\n‚úÖ Ho√†n th√†nh ti·ªÅn x·ª≠ l√Ω d·ªØ li·ªáu!\")\n",
    "print(f\"S·ªë m·∫´u c√≥ label: {len(labeled_data)}\")\n",
    "print(f\"S·ªë m·∫´u kh√¥ng label: {len(unlabeled_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43f4be8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: 521 m·∫´u\n",
      "Test set: 131 m·∫´u\n",
      "\n",
      "Ph√¢n b·ªë nh√£n trong t·∫≠p train:\n",
      "happy       147\n",
      "surprise    139\n",
      "toxic       110\n",
      "negative     83\n",
      "fear         42\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# T√°ch d·ªØ li·ªáu th√†nh texts v√† labels\n",
    "texts = [item[0] for item in labeled_data]\n",
    "labels = [item[1] for item in labeled_data]\n",
    "\n",
    "# Chia t·∫≠p train/test\n",
    "X_train_text, X_test_text, y_train, y_test = train_test_split(\n",
    "    texts, labels, \n",
    "    test_size=0.2, \n",
    "    random_state=42,\n",
    "    stratify=labels\n",
    ")\n",
    "\n",
    "print(f\"Training set: {len(X_train_text)} m·∫´u\")\n",
    "print(f\"Test set: {len(X_test_text)} m·∫´u\")\n",
    "print(f\"\\nPh√¢n b·ªë nh√£n trong t·∫≠p train:\")\n",
    "print(pd.Series(y_train).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7bcc9cc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ƒêang load PhoBERT model: vinai/phobert-base...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ ƒê√£ load PhoBERT tr√™n cpu\n",
      "‚úÖ ƒê√£ kh·ªüi t·∫°o c√°c encoder:\n",
      "  - BoW\n",
      "  - TF-IDF\n",
      "  - TF-IDF-SVD\n",
      "  - Word2Vec\n",
      "  - FastText\n",
      "  - CharNgram\n",
      "  - PhoBERT\n"
     ]
    }
   ],
   "source": [
    "# Kh·ªüi t·∫°o c√°c encoder\n",
    "encoders = {\n",
    "    'BoW': BagOfWordsEncoder(max_vocab=1000, ngram_config=(1, 2)),\n",
    "    'TF-IDF': TfidfEncoder(max_vocab=1000, ngram_config=(1, 3)),\n",
    "    'TF-IDF-SVD': TfidfEncoder(max_vocab=1000, ngram_config=(1, 3), \n",
    "                               use_reduction=True, reduced_dims=100),\n",
    "    'Word2Vec': Word2VecEncoder(vector_size=100, window_size=5, epochs=10),\n",
    "    'FastText': FastTextEncoder(vector_size=100, window_size=5, epochs=10),\n",
    "    'CharNgram': CharNgramEncoder(max_features=5000, ngram_range=(2, 5)),\n",
    "    'PhoBERT': PhoBertEncoder(model_name='vinai/phobert-base', pooling='mean')\n",
    "}\n",
    "\n",
    "print(\"‚úÖ ƒê√£ kh·ªüi t·∫°o c√°c encoder:\")\n",
    "for name in encoders.keys():\n",
    "    print(f\"  - {name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f77697e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ ƒê√£ kh·ªüi t·∫°o ML Trainer v√† Experiment Logger\n",
      "\n",
      "C√°c thu·∫≠t to√°n s·∫Ω ƒë∆∞·ª£c ƒë√°nh gi√°:\n",
      "  - MultinomialNB\n",
      "  - LogisticRegressor\n",
      "  - RidgeClassifier\n",
      "  - DecisionTree\n",
      "  - RandomForest\n",
      "  - AdaBoost\n",
      "  - KNN\n",
      "  - SVM-Linear\n",
      "  - SVM-RBF\n"
     ]
    }
   ],
   "source": [
    "# Kh·ªüi t·∫°o trainer v√† logger\n",
    "trainer = MLTrainer()\n",
    "logger = ExperimentLogger()\n",
    "evaluator = PerformanceEvaluator()\n",
    "\n",
    "print(\"‚úÖ ƒê√£ kh·ªüi t·∫°o ML Trainer v√† Experiment Logger\")\n",
    "print(f\"\\nC√°c thu·∫≠t to√°n s·∫Ω ƒë∆∞·ª£c ƒë√°nh gi√°:\")\n",
    "for algo_name in trainer.algorithms.keys():\n",
    "    print(f\"  - {algo_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "43931630",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "üéØ B·∫ÆT ƒê·∫¶U X·ª¨ L√ù ENCODER: BoW\n",
      "================================================================================\n",
      "\n",
      "üìù ƒêang hu·∫•n luy·ªán BoW...\n",
      "‚úÖ Ho√†n th√†nh! Shape: Train=(521, 366), Test=(131, 366)\n",
      "\n",
      "======================================================================\n",
      "ƒê√ÅNH GI√Å V·ªöI FEATURE: BoW\n",
      "======================================================================\n",
      "\n",
      "MultinomialNB:\n",
      "  Accuracy:  0.7786\n",
      "  F1-Score:  0.7780\n",
      "  Precision: 0.7990\n",
      "  Recall:    0.7786\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fear       0.75      0.60      0.67        10\n",
      "       happy       0.72      0.92      0.81        37\n",
      "    negative       0.62      0.71      0.67        21\n",
      "    surprise       0.88      0.83      0.85        35\n",
      "       toxic       0.95      0.64      0.77        28\n",
      "\n",
      "    accuracy                           0.78       131\n",
      "   macro avg       0.78      0.74      0.75       131\n",
      "weighted avg       0.80      0.78      0.78       131\n",
      "\n",
      "\n",
      "LogisticRegressor:\n",
      "  Accuracy:  0.8092\n",
      "  F1-Score:  0.8064\n",
      "  Precision: 0.8082\n",
      "  Recall:    0.8092\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fear       0.80      0.80      0.80        10\n",
      "       happy       0.84      0.84      0.84        37\n",
      "    negative       0.76      0.62      0.68        21\n",
      "    surprise       0.80      0.91      0.85        35\n",
      "       toxic       0.81      0.79      0.80        28\n",
      "\n",
      "    accuracy                           0.81       131\n",
      "   macro avg       0.80      0.79      0.80       131\n",
      "weighted avg       0.81      0.81      0.81       131\n",
      "\n",
      "\n",
      "RidgeClassifier:\n",
      "  Accuracy:  0.7481\n",
      "  F1-Score:  0.7405\n",
      "  Precision: 0.7407\n",
      "  Recall:    0.7481\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fear       0.57      0.40      0.47        10\n",
      "       happy       0.82      0.84      0.83        37\n",
      "    negative       0.67      0.57      0.62        21\n",
      "    surprise       0.76      0.91      0.83        35\n",
      "       toxic       0.73      0.68      0.70        28\n",
      "\n",
      "    accuracy                           0.75       131\n",
      "   macro avg       0.71      0.68      0.69       131\n",
      "weighted avg       0.74      0.75      0.74       131\n",
      "\n",
      "\n",
      "DecisionTree:\n",
      "  Accuracy:  0.5649\n",
      "  F1-Score:  0.5641\n",
      "  Precision: 0.6369\n",
      "  Recall:    0.5649\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fear       0.50      0.30      0.38        10\n",
      "       happy       0.63      0.51      0.57        37\n",
      "    negative       0.71      0.48      0.57        21\n",
      "    surprise       0.81      0.49      0.61        35\n",
      "       toxic       0.42      0.89      0.57        28\n",
      "\n",
      "    accuracy                           0.56       131\n",
      "   macro avg       0.61      0.53      0.54       131\n",
      "weighted avg       0.64      0.56      0.56       131\n",
      "\n",
      "\n",
      "RandomForest:\n",
      "  Accuracy:  0.6565\n",
      "  F1-Score:  0.6293\n",
      "  Precision: 0.7412\n",
      "  Recall:    0.6565\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fear       1.00      0.10      0.18        10\n",
      "       happy       0.67      0.84      0.75        37\n",
      "    negative       0.82      0.43      0.56        21\n",
      "    surprise       0.54      0.91      0.68        35\n",
      "       toxic       0.93      0.46      0.62        28\n",
      "\n",
      "    accuracy                           0.66       131\n",
      "   macro avg       0.79      0.55      0.56       131\n",
      "weighted avg       0.74      0.66      0.63       131\n",
      "\n",
      "\n",
      "AdaBoost:\n",
      "  Accuracy:  0.5496\n",
      "  F1-Score:  0.5350\n",
      "  Precision: 0.5666\n",
      "  Recall:    0.5496\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fear       0.80      0.40      0.53        10\n",
      "       happy       0.70      0.62      0.66        37\n",
      "    negative       0.50      0.29      0.36        21\n",
      "    surprise       0.49      0.83      0.62        35\n",
      "       toxic       0.45      0.36      0.40        28\n",
      "\n",
      "    accuracy                           0.55       131\n",
      "   macro avg       0.59      0.50      0.51       131\n",
      "weighted avg       0.57      0.55      0.53       131\n",
      "\n",
      "\n",
      "KNN:\n",
      "  Accuracy:  0.5954\n",
      "  F1-Score:  0.5769\n",
      "  Precision: 0.6108\n",
      "  Recall:    0.5954\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fear       0.50      0.20      0.29        10\n",
      "       happy       0.64      0.62      0.63        37\n",
      "    negative       0.78      0.33      0.47        21\n",
      "    surprise       0.59      0.86      0.70        35\n",
      "       toxic       0.52      0.57      0.54        28\n",
      "\n",
      "    accuracy                           0.60       131\n",
      "   macro avg       0.60      0.52      0.52       131\n",
      "weighted avg       0.61      0.60      0.58       131\n",
      "\n",
      "\n",
      "SVM-Linear:\n",
      "  Accuracy:  0.7863\n",
      "  F1-Score:  0.7822\n",
      "  Precision: 0.7835\n",
      "  Recall:    0.7863\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fear       0.75      0.60      0.67        10\n",
      "       happy       0.85      0.89      0.87        37\n",
      "    negative       0.72      0.62      0.67        21\n",
      "    surprise       0.78      0.89      0.83        35\n",
      "       toxic       0.77      0.71      0.74        28\n",
      "\n",
      "    accuracy                           0.79       131\n",
      "   macro avg       0.77      0.74      0.75       131\n",
      "weighted avg       0.78      0.79      0.78       131\n",
      "\n",
      "\n",
      "SVM-RBF:\n",
      "  Accuracy:  0.7252\n",
      "  F1-Score:  0.7214\n",
      "  Precision: 0.7388\n",
      "  Recall:    0.7252\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fear       1.00      0.50      0.67        10\n",
      "       happy       0.70      0.84      0.77        37\n",
      "    negative       0.76      0.62      0.68        21\n",
      "    surprise       0.70      0.80      0.75        35\n",
      "       toxic       0.72      0.64      0.68        28\n",
      "\n",
      "    accuracy                           0.73       131\n",
      "   macro avg       0.78      0.68      0.71       131\n",
      "weighted avg       0.74      0.73      0.72       131\n",
      "\n",
      "\n",
      "Model t·ªët nh·∫•t cho BoW: LogisticRegressor (Accuracy: 0.8092)\n",
      "\n",
      "Confusion Matrix cho model t·ªët nh·∫•t (LogisticRegressor):\n",
      "[[ 8  0  1  1  0]\n",
      " [ 0 31  0  2  4]\n",
      " [ 2  3 13  2  1]\n",
      " [ 0  3  0 32  0]\n",
      " [ 0  0  3  3 22]]\n",
      "\n",
      "================================================================================\n",
      "üéØ B·∫ÆT ƒê·∫¶U X·ª¨ L√ù ENCODER: TF-IDF\n",
      "================================================================================\n",
      "\n",
      "üìù ƒêang hu·∫•n luy·ªán TF-IDF...\n",
      "‚úÖ Ho√†n th√†nh! Shape: Train=(521, 507), Test=(131, 507)\n",
      "\n",
      "======================================================================\n",
      "ƒê√ÅNH GI√Å V·ªöI FEATURE: TF-IDF\n",
      "======================================================================\n",
      "\n",
      "MultinomialNB:\n",
      "  Accuracy:  0.7786\n",
      "  F1-Score:  0.7768\n",
      "  Precision: 0.7785\n",
      "  Recall:    0.7786\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fear       0.62      0.50      0.56        10\n",
      "       happy       0.76      0.86      0.81        37\n",
      "    negative       0.67      0.67      0.67        21\n",
      "    surprise       0.85      0.83      0.84        35\n",
      "       toxic       0.85      0.79      0.81        28\n",
      "\n",
      "    accuracy                           0.78       131\n",
      "   macro avg       0.75      0.73      0.74       131\n",
      "weighted avg       0.78      0.78      0.78       131\n",
      "\n",
      "\n",
      "LogisticRegressor:\n",
      "  Accuracy:  0.7634\n",
      "  F1-Score:  0.7420\n",
      "  Precision: 0.7488\n",
      "  Recall:    0.7634\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fear       0.50      0.10      0.17        10\n",
      "       happy       0.74      0.92      0.82        37\n",
      "    negative       0.78      0.67      0.72        21\n",
      "    surprise       0.79      0.86      0.82        35\n",
      "       toxic       0.78      0.75      0.76        28\n",
      "\n",
      "    accuracy                           0.76       131\n",
      "   macro avg       0.72      0.66      0.66       131\n",
      "weighted avg       0.75      0.76      0.74       131\n",
      "\n",
      "\n",
      "RidgeClassifier:\n",
      "  Accuracy:  0.7634\n",
      "  F1-Score:  0.7585\n",
      "  Precision: 0.7606\n",
      "  Recall:    0.7634\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fear       0.57      0.40      0.47        10\n",
      "       happy       0.75      0.89      0.81        37\n",
      "    negative       0.65      0.62      0.63        21\n",
      "    surprise       0.83      0.83      0.83        35\n",
      "       toxic       0.84      0.75      0.79        28\n",
      "\n",
      "    accuracy                           0.76       131\n",
      "   macro avg       0.73      0.70      0.71       131\n",
      "weighted avg       0.76      0.76      0.76       131\n",
      "\n",
      "\n",
      "DecisionTree:\n",
      "  Accuracy:  0.5344\n",
      "  F1-Score:  0.5330\n",
      "  Precision: 0.5981\n",
      "  Recall:    0.5344\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fear       0.43      0.30      0.35        10\n",
      "       happy       0.59      0.43      0.50        37\n",
      "    negative       0.77      0.48      0.59        21\n",
      "    surprise       0.71      0.49      0.58        35\n",
      "       toxic       0.40      0.86      0.55        28\n",
      "\n",
      "    accuracy                           0.53       131\n",
      "   macro avg       0.58      0.51      0.51       131\n",
      "weighted avg       0.60      0.53      0.53       131\n",
      "\n",
      "\n",
      "RandomForest:\n",
      "  Accuracy:  0.6947\n",
      "  F1-Score:  0.6598\n",
      "  Precision: 0.6851\n",
      "  Recall:    0.6947\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fear       0.00      0.00      0.00        10\n",
      "       happy       0.65      0.92      0.76        37\n",
      "    negative       0.83      0.48      0.61        21\n",
      "    surprise       0.62      0.89      0.73        35\n",
      "       toxic       0.94      0.57      0.71        28\n",
      "\n",
      "    accuracy                           0.69       131\n",
      "   macro avg       0.61      0.57      0.56       131\n",
      "weighted avg       0.69      0.69      0.66       131\n",
      "\n",
      "\n",
      "AdaBoost:\n",
      "  Accuracy:  0.5420\n",
      "  F1-Score:  0.5075\n",
      "  Precision: 0.5553\n",
      "  Recall:    0.5420\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fear       1.00      0.20      0.33        10\n",
      "       happy       0.57      0.76      0.65        37\n",
      "    negative       0.46      0.29      0.35        21\n",
      "    surprise       0.54      0.80      0.64        35\n",
      "       toxic       0.47      0.25      0.33        28\n",
      "\n",
      "    accuracy                           0.54       131\n",
      "   macro avg       0.61      0.46      0.46       131\n",
      "weighted avg       0.56      0.54      0.51       131\n",
      "\n",
      "\n",
      "KNN:\n",
      "  Accuracy:  0.6336\n",
      "  F1-Score:  0.6063\n",
      "  Precision: 0.6489\n",
      "  Recall:    0.6336\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fear       0.00      0.00      0.00        10\n",
      "       happy       0.77      0.65      0.71        37\n",
      "    negative       0.89      0.38      0.53        21\n",
      "    surprise       0.49      0.91      0.64        35\n",
      "       toxic       0.73      0.68      0.70        28\n",
      "\n",
      "    accuracy                           0.63       131\n",
      "   macro avg       0.58      0.52      0.52       131\n",
      "weighted avg       0.65      0.63      0.61       131\n",
      "\n",
      "\n",
      "SVM-Linear:\n",
      "  Accuracy:  0.7710\n",
      "  F1-Score:  0.7667\n",
      "  Precision: 0.7695\n",
      "  Recall:    0.7710\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fear       0.57      0.40      0.47        10\n",
      "       happy       0.77      0.89      0.82        37\n",
      "    negative       0.64      0.67      0.65        21\n",
      "    surprise       0.86      0.86      0.86        35\n",
      "       toxic       0.83      0.71      0.77        28\n",
      "\n",
      "    accuracy                           0.77       131\n",
      "   macro avg       0.73      0.71      0.71       131\n",
      "weighted avg       0.77      0.77      0.77       131\n",
      "\n",
      "\n",
      "SVM-RBF:\n",
      "  Accuracy:  0.7634\n",
      "  F1-Score:  0.7499\n",
      "  Precision: 0.7529\n",
      "  Recall:    0.7634\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fear       0.50      0.20      0.29        10\n",
      "       happy       0.74      0.92      0.82        37\n",
      "    negative       0.74      0.67      0.70        21\n",
      "    surprise       0.81      0.83      0.82        35\n",
      "       toxic       0.81      0.75      0.78        28\n",
      "\n",
      "    accuracy                           0.76       131\n",
      "   macro avg       0.72      0.67      0.68       131\n",
      "weighted avg       0.75      0.76      0.75       131\n",
      "\n",
      "\n",
      "Model t·ªët nh·∫•t cho TF-IDF: MultinomialNB (Accuracy: 0.7786)\n",
      "\n",
      "Confusion Matrix cho model t·ªët nh·∫•t (MultinomialNB):\n",
      "[[ 5  2  1  2  0]\n",
      " [ 0 32  2  1  2]\n",
      " [ 2  2 14  1  2]\n",
      " [ 1  4  1 29  0]\n",
      " [ 0  2  3  1 22]]\n",
      "\n",
      "================================================================================\n",
      "üéØ B·∫ÆT ƒê·∫¶U X·ª¨ L√ù ENCODER: TF-IDF-SVD\n",
      "================================================================================\n",
      "\n",
      "üìù ƒêang hu·∫•n luy·ªán TF-IDF-SVD...\n",
      "‚úÖ Ho√†n th√†nh! Shape: Train=(521, 100), Test=(131, 100)\n",
      "\n",
      "======================================================================\n",
      "ƒê√ÅNH GI√Å V·ªöI FEATURE: TF-IDF-SVD\n",
      "======================================================================\n",
      "\n",
      "MultinomialNB:\n",
      "  Accuracy:  0.6641\n",
      "  F1-Score:  0.6709\n",
      "  Precision: 0.6910\n",
      "  Recall:    0.6641\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fear       0.38      0.50      0.43        10\n",
      "       happy       0.77      0.65      0.71        37\n",
      "    negative       0.48      0.67      0.56        21\n",
      "    surprise       0.75      0.77      0.76        35\n",
      "       toxic       0.77      0.61      0.68        28\n",
      "\n",
      "    accuracy                           0.66       131\n",
      "   macro avg       0.63      0.64      0.63       131\n",
      "weighted avg       0.69      0.66      0.67       131\n",
      "\n",
      "\n",
      "LogisticRegressor:\n",
      "  Accuracy:  0.7863\n",
      "  F1-Score:  0.7688\n",
      "  Precision: 0.8026\n",
      "  Recall:    0.7863\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fear       1.00      0.20      0.33        10\n",
      "       happy       0.76      0.92      0.83        37\n",
      "    negative       0.81      0.62      0.70        21\n",
      "    surprise       0.78      0.89      0.83        35\n",
      "       toxic       0.82      0.82      0.82        28\n",
      "\n",
      "    accuracy                           0.79       131\n",
      "   macro avg       0.83      0.69      0.70       131\n",
      "weighted avg       0.80      0.79      0.77       131\n",
      "\n",
      "\n",
      "RidgeClassifier:\n",
      "  Accuracy:  0.7634\n",
      "  F1-Score:  0.7539\n",
      "  Precision: 0.7594\n",
      "  Recall:    0.7634\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fear       0.60      0.30      0.40        10\n",
      "       happy       0.77      0.92      0.84        37\n",
      "    negative       0.68      0.62      0.65        21\n",
      "    surprise       0.74      0.83      0.78        35\n",
      "       toxic       0.88      0.75      0.81        28\n",
      "\n",
      "    accuracy                           0.76       131\n",
      "   macro avg       0.74      0.68      0.70       131\n",
      "weighted avg       0.76      0.76      0.75       131\n",
      "\n",
      "\n",
      "DecisionTree:\n",
      "  Accuracy:  0.5038\n",
      "  F1-Score:  0.5032\n",
      "  Precision: 0.5145\n",
      "  Recall:    0.5038\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fear       0.29      0.20      0.24        10\n",
      "       happy       0.53      0.54      0.53        37\n",
      "    negative       0.55      0.52      0.54        21\n",
      "    surprise       0.63      0.49      0.55        35\n",
      "       toxic       0.41      0.57      0.48        28\n",
      "\n",
      "    accuracy                           0.50       131\n",
      "   macro avg       0.48      0.46      0.47       131\n",
      "weighted avg       0.51      0.50      0.50       131\n",
      "\n",
      "\n",
      "RandomForest:\n",
      "  Accuracy:  0.6947\n",
      "  F1-Score:  0.6702\n",
      "  Precision: 0.6580\n",
      "  Recall:    0.6947\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fear       0.00      0.00      0.00        10\n",
      "       happy       0.62      0.81      0.71        37\n",
      "    negative       0.81      0.62      0.70        21\n",
      "    surprise       0.69      0.77      0.73        35\n",
      "       toxic       0.78      0.75      0.76        28\n",
      "\n",
      "    accuracy                           0.69       131\n",
      "   macro avg       0.58      0.59      0.58       131\n",
      "weighted avg       0.66      0.69      0.67       131\n",
      "\n",
      "\n",
      "AdaBoost:\n",
      "  Accuracy:  0.4962\n",
      "  F1-Score:  0.4635\n",
      "  Precision: 0.4525\n",
      "  Recall:    0.4962\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fear       0.00      0.00      0.00        10\n",
      "       happy       0.52      0.59      0.56        37\n",
      "    negative       0.40      0.19      0.26        21\n",
      "    surprise       0.50      0.54      0.52        35\n",
      "       toxic       0.50      0.71      0.59        28\n",
      "\n",
      "    accuracy                           0.50       131\n",
      "   macro avg       0.38      0.41      0.38       131\n",
      "weighted avg       0.45      0.50      0.46       131\n",
      "\n",
      "\n",
      "KNN:\n",
      "  Accuracy:  0.7099\n",
      "  F1-Score:  0.6967\n",
      "  Precision: 0.7106\n",
      "  Recall:    0.7099\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fear       0.50      0.20      0.29        10\n",
      "       happy       0.75      0.81      0.78        37\n",
      "    negative       0.85      0.52      0.65        21\n",
      "    surprise       0.68      0.80      0.74        35\n",
      "       toxic       0.67      0.79      0.72        28\n",
      "\n",
      "    accuracy                           0.71       131\n",
      "   macro avg       0.69      0.62      0.63       131\n",
      "weighted avg       0.71      0.71      0.70       131\n",
      "\n",
      "\n",
      "SVM-Linear:\n",
      "  Accuracy:  0.7786\n",
      "  F1-Score:  0.7738\n",
      "  Precision: 0.7761\n",
      "  Recall:    0.7786\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fear       0.57      0.40      0.47        10\n",
      "       happy       0.79      0.92      0.85        37\n",
      "    negative       0.67      0.67      0.67        21\n",
      "    surprise       0.81      0.83      0.82        35\n",
      "       toxic       0.88      0.75      0.81        28\n",
      "\n",
      "    accuracy                           0.78       131\n",
      "   macro avg       0.74      0.71      0.72       131\n",
      "weighted avg       0.78      0.78      0.77       131\n",
      "\n",
      "\n",
      "SVM-RBF:\n",
      "  Accuracy:  0.8015\n",
      "  F1-Score:  0.7953\n",
      "  Precision: 0.7971\n",
      "  Recall:    0.8015\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fear       0.67      0.40      0.50        10\n",
      "       happy       0.81      0.92      0.86        37\n",
      "    negative       0.74      0.67      0.70        21\n",
      "    surprise       0.78      0.83      0.81        35\n",
      "       toxic       0.89      0.86      0.87        28\n",
      "\n",
      "    accuracy                           0.80       131\n",
      "   macro avg       0.78      0.73      0.75       131\n",
      "weighted avg       0.80      0.80      0.80       131\n",
      "\n",
      "\n",
      "Model t·ªët nh·∫•t cho TF-IDF-SVD: SVM-RBF (Accuracy: 0.8015)\n",
      "\n",
      "Confusion Matrix cho model t·ªët nh·∫•t (SVM-RBF):\n",
      "[[ 4  2  1  3  0]\n",
      " [ 0 34  1  1  1]\n",
      " [ 1  2 14  2  2]\n",
      " [ 1  4  1 29  0]\n",
      " [ 0  0  2  2 24]]\n",
      "\n",
      "================================================================================\n",
      "üéØ B·∫ÆT ƒê·∫¶U X·ª¨ L√ù ENCODER: Word2Vec\n",
      "================================================================================\n",
      "\n",
      "üìù ƒêang hu·∫•n luy·ªán Word2Vec...\n",
      "‚úÖ Ho√†n th√†nh! Shape: Train=(521, 100), Test=(131, 100)\n",
      "\n",
      "======================================================================\n",
      "ƒê√ÅNH GI√Å V·ªöI FEATURE: Word2Vec\n",
      "======================================================================\n",
      "\n",
      "MultinomialNB:\n",
      "  Accuracy:  0.2672\n",
      "  F1-Score:  0.2760\n",
      "  Precision: 0.3939\n",
      "  Recall:    0.2672\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fear       0.11      0.50      0.18        10\n",
      "       happy       0.35      0.22      0.27        37\n",
      "    negative       0.25      0.43      0.32        21\n",
      "    surprise       0.53      0.29      0.37        35\n",
      "       toxic       0.50      0.11      0.18        28\n",
      "\n",
      "    accuracy                           0.27       131\n",
      "   macro avg       0.35      0.31      0.26       131\n",
      "weighted avg       0.39      0.27      0.28       131\n",
      "\n",
      "\n",
      "LogisticRegressor:\n",
      "  Accuracy:  0.3359\n",
      "  F1-Score:  0.2349\n",
      "  Precision: 0.1974\n",
      "  Recall:    0.3359\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fear       0.00      0.00      0.00        10\n",
      "       happy       0.31      0.81      0.45        37\n",
      "    negative       0.00      0.00      0.00        21\n",
      "    surprise       0.41      0.40      0.41        35\n",
      "       toxic       0.00      0.00      0.00        28\n",
      "\n",
      "    accuracy                           0.34       131\n",
      "   macro avg       0.14      0.24      0.17       131\n",
      "weighted avg       0.20      0.34      0.23       131\n",
      "\n",
      "\n",
      "RidgeClassifier:\n",
      "  Accuracy:  0.3359\n",
      "  F1-Score:  0.2333\n",
      "  Precision: 0.1912\n",
      "  Recall:    0.3359\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fear       0.00      0.00      0.00        10\n",
      "       happy       0.32      0.81      0.46        37\n",
      "    negative       0.00      0.00      0.00        21\n",
      "    surprise       0.38      0.40      0.39        35\n",
      "       toxic       0.00      0.00      0.00        28\n",
      "\n",
      "    accuracy                           0.34       131\n",
      "   macro avg       0.14      0.24      0.17       131\n",
      "weighted avg       0.19      0.34      0.23       131\n",
      "\n",
      "\n",
      "DecisionTree:\n",
      "  Accuracy:  0.4351\n",
      "  F1-Score:  0.4335\n",
      "  Precision: 0.4355\n",
      "  Recall:    0.4351\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fear       0.27      0.30      0.29        10\n",
      "       happy       0.41      0.46      0.44        37\n",
      "    negative       0.41      0.33      0.37        21\n",
      "    surprise       0.50      0.54      0.52        35\n",
      "       toxic       0.46      0.39      0.42        28\n",
      "\n",
      "    accuracy                           0.44       131\n",
      "   macro avg       0.41      0.41      0.41       131\n",
      "weighted avg       0.44      0.44      0.43       131\n",
      "\n",
      "\n",
      "RandomForest:\n",
      "  Accuracy:  0.5420\n",
      "  F1-Score:  0.5215\n",
      "  Precision: 0.5717\n",
      "  Recall:    0.5420\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fear       1.00      0.10      0.18        10\n",
      "       happy       0.50      0.68      0.57        37\n",
      "    negative       0.46      0.29      0.35        21\n",
      "    surprise       0.65      0.69      0.67        35\n",
      "       toxic       0.50      0.54      0.52        28\n",
      "\n",
      "    accuracy                           0.54       131\n",
      "   macro avg       0.62      0.46      0.46       131\n",
      "weighted avg       0.57      0.54      0.52       131\n",
      "\n",
      "\n",
      "AdaBoost:\n",
      "  Accuracy:  0.3740\n",
      "  F1-Score:  0.3581\n",
      "  Precision: 0.3673\n",
      "  Recall:    0.3740\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fear       0.00      0.00      0.00        10\n",
      "       happy       0.34      0.51      0.41        37\n",
      "    negative       0.50      0.24      0.32        21\n",
      "    surprise       0.53      0.51      0.52        35\n",
      "       toxic       0.23      0.25      0.24        28\n",
      "\n",
      "    accuracy                           0.37       131\n",
      "   macro avg       0.32      0.30      0.30       131\n",
      "weighted avg       0.37      0.37      0.36       131\n",
      "\n",
      "\n",
      "KNN:\n",
      "  Accuracy:  0.3817\n",
      "  F1-Score:  0.3875\n",
      "  Precision: 0.4082\n",
      "  Recall:    0.3817\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fear       0.27      0.40      0.32        10\n",
      "       happy       0.35      0.35      0.35        37\n",
      "    negative       0.26      0.29      0.27        21\n",
      "    surprise       0.61      0.40      0.48        35\n",
      "       toxic       0.39      0.46      0.43        28\n",
      "\n",
      "    accuracy                           0.38       131\n",
      "   macro avg       0.38      0.38      0.37       131\n",
      "weighted avg       0.41      0.38      0.39       131\n",
      "\n",
      "\n",
      "SVM-Linear:\n",
      "  Accuracy:  0.3359\n",
      "  F1-Score:  0.2349\n",
      "  Precision: 0.1974\n",
      "  Recall:    0.3359\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fear       0.00      0.00      0.00        10\n",
      "       happy       0.31      0.81      0.45        37\n",
      "    negative       0.00      0.00      0.00        21\n",
      "    surprise       0.41      0.40      0.41        35\n",
      "       toxic       0.00      0.00      0.00        28\n",
      "\n",
      "    accuracy                           0.34       131\n",
      "   macro avg       0.14      0.24      0.17       131\n",
      "weighted avg       0.20      0.34      0.23       131\n",
      "\n",
      "\n",
      "SVM-RBF:\n",
      "  Accuracy:  0.2977\n",
      "  F1-Score:  0.1548\n",
      "  Precision: 0.2598\n",
      "  Recall:    0.2977\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fear       0.00      0.00      0.00        10\n",
      "       happy       0.29      1.00      0.45        37\n",
      "    negative       0.00      0.00      0.00        21\n",
      "    surprise       0.67      0.06      0.11        35\n",
      "       toxic       0.00      0.00      0.00        28\n",
      "\n",
      "    accuracy                           0.30       131\n",
      "   macro avg       0.19      0.21      0.11       131\n",
      "weighted avg       0.26      0.30      0.15       131\n",
      "\n",
      "\n",
      "Model t·ªët nh·∫•t cho Word2Vec: RandomForest (Accuracy: 0.5420)\n",
      "\n",
      "Confusion Matrix cho model t·ªët nh·∫•t (RandomForest):\n",
      "[[ 1  6  1  1  1]\n",
      " [ 0 25  3  3  6]\n",
      " [ 0  8  6  2  5]\n",
      " [ 0  7  1 24  3]\n",
      " [ 0  4  2  7 15]]\n",
      "\n",
      "================================================================================\n",
      "üéØ B·∫ÆT ƒê·∫¶U X·ª¨ L√ù ENCODER: FastText\n",
      "================================================================================\n",
      "\n",
      "üìù ƒêang hu·∫•n luy·ªán FastText...\n",
      "‚úÖ Ho√†n th√†nh! Shape: Train=(521, 100), Test=(131, 100)\n",
      "\n",
      "======================================================================\n",
      "ƒê√ÅNH GI√Å V·ªöI FEATURE: FastText\n",
      "======================================================================\n",
      "\n",
      "MultinomialNB:\n",
      "  Accuracy:  0.3511\n",
      "  F1-Score:  0.3611\n",
      "  Precision: 0.4261\n",
      "  Recall:    0.3511\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fear       0.16      0.70      0.25        10\n",
      "       happy       0.32      0.32      0.32        37\n",
      "    negative       0.14      0.05      0.07        21\n",
      "    surprise       0.68      0.43      0.53        35\n",
      "       toxic       0.55      0.39      0.46        28\n",
      "\n",
      "    accuracy                           0.35       131\n",
      "   macro avg       0.37      0.38      0.33       131\n",
      "weighted avg       0.43      0.35      0.36       131\n",
      "\n",
      "\n",
      "LogisticRegressor:\n",
      "  Accuracy:  0.3206\n",
      "  F1-Score:  0.1934\n",
      "  Precision: 0.2751\n",
      "  Recall:    0.3206\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fear       0.00      0.00      0.00        10\n",
      "       happy       0.30      1.00      0.46        37\n",
      "    negative       0.00      0.00      0.00        21\n",
      "    surprise       0.71      0.14      0.24        35\n",
      "       toxic       0.00      0.00      0.00        28\n",
      "\n",
      "    accuracy                           0.32       131\n",
      "   macro avg       0.20      0.23      0.14       131\n",
      "weighted avg       0.28      0.32      0.19       131\n",
      "\n",
      "\n",
      "RidgeClassifier:\n",
      "  Accuracy:  0.3664\n",
      "  F1-Score:  0.2540\n",
      "  Precision: 0.2322\n",
      "  Recall:    0.3664\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fear       0.00      0.00      0.00        10\n",
      "       happy       0.33      0.95      0.49        37\n",
      "    negative       0.00      0.00      0.00        21\n",
      "    surprise       0.52      0.37      0.43        35\n",
      "       toxic       0.00      0.00      0.00        28\n",
      "\n",
      "    accuracy                           0.37       131\n",
      "   macro avg       0.17      0.26      0.18       131\n",
      "weighted avg       0.23      0.37      0.25       131\n",
      "\n",
      "\n",
      "DecisionTree:\n",
      "  Accuracy:  0.3740\n",
      "  F1-Score:  0.3692\n",
      "  Precision: 0.3795\n",
      "  Recall:    0.3740\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fear       0.00      0.00      0.00        10\n",
      "       happy       0.34      0.35      0.35        37\n",
      "    negative       0.29      0.19      0.23        21\n",
      "    surprise       0.56      0.43      0.48        35\n",
      "       toxic       0.41      0.61      0.49        28\n",
      "\n",
      "    accuracy                           0.37       131\n",
      "   macro avg       0.32      0.32      0.31       131\n",
      "weighted avg       0.38      0.37      0.37       131\n",
      "\n",
      "\n",
      "RandomForest:\n",
      "  Accuracy:  0.5954\n",
      "  F1-Score:  0.5553\n",
      "  Precision: 0.6568\n",
      "  Recall:    0.5954\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fear       1.00      0.10      0.18        10\n",
      "       happy       0.51      0.95      0.67        37\n",
      "    negative       0.56      0.24      0.33        21\n",
      "    surprise       0.67      0.74      0.70        35\n",
      "       toxic       0.79      0.39      0.52        28\n",
      "\n",
      "    accuracy                           0.60       131\n",
      "   macro avg       0.70      0.48      0.48       131\n",
      "weighted avg       0.66      0.60      0.56       131\n",
      "\n",
      "\n",
      "AdaBoost:\n",
      "  Accuracy:  0.4198\n",
      "  F1-Score:  0.3967\n",
      "  Precision: 0.4020\n",
      "  Recall:    0.4198\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fear       0.00      0.00      0.00        10\n",
      "       happy       0.40      0.68      0.50        37\n",
      "    negative       0.26      0.24      0.25        21\n",
      "    surprise       0.61      0.49      0.54        35\n",
      "       toxic       0.40      0.29      0.33        28\n",
      "\n",
      "    accuracy                           0.42       131\n",
      "   macro avg       0.33      0.34      0.32       131\n",
      "weighted avg       0.40      0.42      0.40       131\n",
      "\n",
      "\n",
      "KNN:\n",
      "  Accuracy:  0.5496\n",
      "  F1-Score:  0.5455\n",
      "  Precision: 0.5696\n",
      "  Recall:    0.5496\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fear       0.33      0.30      0.32        10\n",
      "       happy       0.53      0.73      0.61        37\n",
      "    negative       0.36      0.24      0.29        21\n",
      "    surprise       0.88      0.60      0.71        35\n",
      "       toxic       0.48      0.57      0.52        28\n",
      "\n",
      "    accuracy                           0.55       131\n",
      "   macro avg       0.52      0.49      0.49       131\n",
      "weighted avg       0.57      0.55      0.55       131\n",
      "\n",
      "\n",
      "SVM-Linear:\n",
      "  Accuracy:  0.3817\n",
      "  F1-Score:  0.2695\n",
      "  Precision: 0.2435\n",
      "  Recall:    0.3817\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fear       0.00      0.00      0.00        10\n",
      "       happy       0.34      0.95      0.50        37\n",
      "    negative       0.00      0.00      0.00        21\n",
      "    surprise       0.56      0.43      0.48        35\n",
      "       toxic       0.00      0.00      0.00        28\n",
      "\n",
      "    accuracy                           0.38       131\n",
      "   macro avg       0.18      0.27      0.20       131\n",
      "weighted avg       0.24      0.38      0.27       131\n",
      "\n",
      "\n",
      "SVM-RBF:\n",
      "  Accuracy:  0.2824\n",
      "  F1-Score:  0.1244\n",
      "  Precision: 0.0798\n",
      "  Recall:    0.2824\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fear       0.00      0.00      0.00        10\n",
      "       happy       0.28      1.00      0.44        37\n",
      "    negative       0.00      0.00      0.00        21\n",
      "    surprise       0.00      0.00      0.00        35\n",
      "       toxic       0.00      0.00      0.00        28\n",
      "\n",
      "    accuracy                           0.28       131\n",
      "   macro avg       0.06      0.20      0.09       131\n",
      "weighted avg       0.08      0.28      0.12       131\n",
      "\n",
      "\n",
      "Model t·ªët nh·∫•t cho FastText: RandomForest (Accuracy: 0.5954)\n",
      "\n",
      "Confusion Matrix cho model t·ªët nh·∫•t (RandomForest):\n",
      "[[ 1  8  0  0  1]\n",
      " [ 0 35  0  2  0]\n",
      " [ 0 13  5  2  1]\n",
      " [ 0  6  2 26  1]\n",
      " [ 0  6  2  9 11]]\n",
      "\n",
      "================================================================================\n",
      "üéØ B·∫ÆT ƒê·∫¶U X·ª¨ L√ù ENCODER: CharNgram\n",
      "================================================================================\n",
      "\n",
      "üìù ƒêang hu·∫•n luy·ªán CharNgram...\n",
      "‚úÖ Ho√†n th√†nh! Shape: Train=(521, 3632), Test=(131, 3632)\n",
      "\n",
      "======================================================================\n",
      "ƒê√ÅNH GI√Å V·ªöI FEATURE: CharNgram\n",
      "======================================================================\n",
      "\n",
      "MultinomialNB:\n",
      "  Accuracy:  0.8626\n",
      "  F1-Score:  0.8642\n",
      "  Precision: 0.8785\n",
      "  Recall:    0.8626\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fear       0.88      0.70      0.78        10\n",
      "       happy       0.83      0.92      0.87        37\n",
      "    negative       0.70      0.90      0.79        21\n",
      "    surprise       0.94      0.89      0.91        35\n",
      "       toxic       1.00      0.79      0.88        28\n",
      "\n",
      "    accuracy                           0.86       131\n",
      "   macro avg       0.87      0.84      0.85       131\n",
      "weighted avg       0.88      0.86      0.86       131\n",
      "\n",
      "\n",
      "LogisticRegressor:\n",
      "  Accuracy:  0.8473\n",
      "  F1-Score:  0.8397\n",
      "  Precision: 0.8576\n",
      "  Recall:    0.8473\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fear       1.00      0.40      0.57        10\n",
      "       happy       0.76      0.92      0.83        37\n",
      "    negative       0.78      0.67      0.72        21\n",
      "    surprise       0.94      0.97      0.96        35\n",
      "       toxic       0.89      0.89      0.89        28\n",
      "\n",
      "    accuracy                           0.85       131\n",
      "   macro avg       0.87      0.77      0.79       131\n",
      "weighted avg       0.86      0.85      0.84       131\n",
      "\n",
      "\n",
      "RidgeClassifier:\n",
      "  Accuracy:  0.8702\n",
      "  F1-Score:  0.8675\n",
      "  Precision: 0.8733\n",
      "  Recall:    0.8702\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fear       0.83      0.50      0.62        10\n",
      "       happy       0.85      0.92      0.88        37\n",
      "    negative       0.75      0.86      0.80        21\n",
      "    surprise       0.94      0.91      0.93        35\n",
      "       toxic       0.93      0.89      0.91        28\n",
      "\n",
      "    accuracy                           0.87       131\n",
      "   macro avg       0.86      0.82      0.83       131\n",
      "weighted avg       0.87      0.87      0.87       131\n",
      "\n",
      "\n",
      "DecisionTree:\n",
      "  Accuracy:  0.5344\n",
      "  F1-Score:  0.5204\n",
      "  Precision: 0.5246\n",
      "  Recall:    0.5344\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fear       0.25      0.40      0.31        10\n",
      "       happy       0.56      0.51      0.54        37\n",
      "    negative       0.33      0.14      0.20        21\n",
      "    surprise       0.59      0.69      0.63        35\n",
      "       toxic       0.65      0.71      0.68        28\n",
      "\n",
      "    accuracy                           0.53       131\n",
      "   macro avg       0.47      0.49      0.47       131\n",
      "weighted avg       0.52      0.53      0.52       131\n",
      "\n",
      "\n",
      "RandomForest:\n",
      "  Accuracy:  0.6947\n",
      "  F1-Score:  0.6783\n",
      "  Precision: 0.7412\n",
      "  Recall:    0.6947\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fear       1.00      0.30      0.46        10\n",
      "       happy       0.65      0.81      0.72        37\n",
      "    negative       0.86      0.57      0.69        21\n",
      "    surprise       0.63      0.94      0.76        35\n",
      "       toxic       0.81      0.46      0.59        28\n",
      "\n",
      "    accuracy                           0.69       131\n",
      "   macro avg       0.79      0.62      0.64       131\n",
      "weighted avg       0.74      0.69      0.68       131\n",
      "\n",
      "\n",
      "AdaBoost:\n",
      "  Accuracy:  0.4198\n",
      "  F1-Score:  0.3720\n",
      "  Precision: 0.4793\n",
      "  Recall:    0.4198\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fear       1.00      0.20      0.33        10\n",
      "       happy       0.39      0.76      0.52        37\n",
      "    negative       0.45      0.24      0.31        21\n",
      "    surprise       0.42      0.51      0.46        35\n",
      "       toxic       0.50      0.07      0.12        28\n",
      "\n",
      "    accuracy                           0.42       131\n",
      "   macro avg       0.55      0.36      0.35       131\n",
      "weighted avg       0.48      0.42      0.37       131\n",
      "\n",
      "\n",
      "KNN:\n",
      "  Accuracy:  0.8550\n",
      "  F1-Score:  0.8487\n",
      "  Precision: 0.8583\n",
      "  Recall:    0.8550\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fear       0.80      0.40      0.53        10\n",
      "       happy       0.81      0.95      0.88        37\n",
      "    negative       0.83      0.90      0.86        21\n",
      "    surprise       0.86      0.89      0.87        35\n",
      "       toxic       0.96      0.82      0.88        28\n",
      "\n",
      "    accuracy                           0.85       131\n",
      "   macro avg       0.85      0.79      0.81       131\n",
      "weighted avg       0.86      0.85      0.85       131\n",
      "\n",
      "\n",
      "SVM-Linear:\n",
      "  Accuracy:  0.9008\n",
      "  F1-Score:  0.9031\n",
      "  Precision: 0.9081\n",
      "  Recall:    0.9008\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fear       0.80      0.80      0.80        10\n",
      "       happy       0.94      0.92      0.93        37\n",
      "    negative       0.72      0.86      0.78        21\n",
      "    surprise       0.97      0.94      0.96        35\n",
      "       toxic       0.96      0.89      0.93        28\n",
      "\n",
      "    accuracy                           0.90       131\n",
      "   macro avg       0.88      0.88      0.88       131\n",
      "weighted avg       0.91      0.90      0.90       131\n",
      "\n",
      "\n",
      "SVM-RBF:\n",
      "  Accuracy:  0.8779\n",
      "  F1-Score:  0.8692\n",
      "  Precision: 0.8858\n",
      "  Recall:    0.8779\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fear       1.00      0.40      0.57        10\n",
      "       happy       0.80      0.95      0.86        37\n",
      "    negative       0.83      0.71      0.77        21\n",
      "    surprise       0.95      1.00      0.97        35\n",
      "       toxic       0.93      0.93      0.93        28\n",
      "\n",
      "    accuracy                           0.88       131\n",
      "   macro avg       0.90      0.80      0.82       131\n",
      "weighted avg       0.89      0.88      0.87       131\n",
      "\n",
      "\n",
      "Model t·ªët nh·∫•t cho CharNgram: SVM-Linear (Accuracy: 0.9008)\n",
      "\n",
      "Confusion Matrix cho model t·ªët nh·∫•t (SVM-Linear):\n",
      "[[ 8  2  0  0  0]\n",
      " [ 0 34  3  0  0]\n",
      " [ 2  0 18  0  1]\n",
      " [ 0  0  2 33  0]\n",
      " [ 0  0  2  1 25]]\n",
      "\n",
      "================================================================================\n",
      "üéØ B·∫ÆT ƒê·∫¶U X·ª¨ L√ù ENCODER: PhoBERT\n",
      "================================================================================\n",
      "\n",
      "üìù ƒêang hu·∫•n luy·ªán PhoBERT...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BERT Encoding: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 33/33 [00:16<00:00,  2.05it/s]\n",
      "BERT Encoding: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9/9 [00:04<00:00,  2.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Ho√†n th√†nh! Shape: Train=(521, 768), Test=(131, 768)\n",
      "\n",
      "======================================================================\n",
      "ƒê√ÅNH GI√Å V·ªöI FEATURE: PhoBERT\n",
      "======================================================================\n",
      "\n",
      "MultinomialNB:\n",
      "  Accuracy:  0.3740\n",
      "  F1-Score:  0.3567\n",
      "  Precision: 0.4477\n",
      "  Recall:    0.3740\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fear       0.20      0.90      0.32        10\n",
      "       happy       0.33      0.08      0.13        37\n",
      "    negative       0.29      0.33      0.31        21\n",
      "    surprise       0.54      0.60      0.57        35\n",
      "       toxic       0.69      0.32      0.44        28\n",
      "\n",
      "    accuracy                           0.37       131\n",
      "   macro avg       0.41      0.45      0.35       131\n",
      "weighted avg       0.45      0.37      0.36       131\n",
      "\n",
      "\n",
      "LogisticRegressor:\n",
      "  Accuracy:  0.7328\n",
      "  F1-Score:  0.7296\n",
      "  Precision: 0.7319\n",
      "  Recall:    0.7328\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fear       0.60      0.60      0.60        10\n",
      "       happy       0.74      0.86      0.80        37\n",
      "    negative       0.65      0.62      0.63        21\n",
      "    surprise       0.80      0.80      0.80        35\n",
      "       toxic       0.74      0.61      0.67        28\n",
      "\n",
      "    accuracy                           0.73       131\n",
      "   macro avg       0.71      0.70      0.70       131\n",
      "weighted avg       0.73      0.73      0.73       131\n",
      "\n",
      "\n",
      "RidgeClassifier:\n",
      "  Accuracy:  0.7634\n",
      "  F1-Score:  0.7594\n",
      "  Precision: 0.7658\n",
      "  Recall:    0.7634\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fear       0.88      0.70      0.78        10\n",
      "       happy       0.74      0.86      0.80        37\n",
      "    negative       0.73      0.76      0.74        21\n",
      "    surprise       0.78      0.83      0.81        35\n",
      "       toxic       0.76      0.57      0.65        28\n",
      "\n",
      "    accuracy                           0.76       131\n",
      "   macro avg       0.78      0.75      0.76       131\n",
      "weighted avg       0.77      0.76      0.76       131\n",
      "\n",
      "\n",
      "DecisionTree:\n",
      "  Accuracy:  0.4046\n",
      "  F1-Score:  0.4123\n",
      "  Precision: 0.4249\n",
      "  Recall:    0.4046\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fear       0.00      0.00      0.00        10\n",
      "       happy       0.55      0.43      0.48        37\n",
      "    negative       0.29      0.33      0.31        21\n",
      "    surprise       0.60      0.60      0.60        35\n",
      "       toxic       0.29      0.32      0.31        28\n",
      "\n",
      "    accuracy                           0.40       131\n",
      "   macro avg       0.35      0.34      0.34       131\n",
      "weighted avg       0.42      0.40      0.41       131\n",
      "\n",
      "\n",
      "RandomForest:\n",
      "  Accuracy:  0.5344\n",
      "  F1-Score:  0.5005\n",
      "  Precision: 0.5422\n",
      "  Recall:    0.5344\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fear       0.50      0.10      0.17        10\n",
      "       happy       0.45      0.76      0.57        37\n",
      "    negative       0.50      0.14      0.22        21\n",
      "    surprise       0.68      0.71      0.69        35\n",
      "       toxic       0.54      0.46      0.50        28\n",
      "\n",
      "    accuracy                           0.53       131\n",
      "   macro avg       0.53      0.44      0.43       131\n",
      "weighted avg       0.54      0.53      0.50       131\n",
      "\n",
      "\n",
      "AdaBoost:\n",
      "  Accuracy:  0.4046\n",
      "  F1-Score:  0.3983\n",
      "  Precision: 0.4080\n",
      "  Recall:    0.4046\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fear       0.42      0.50      0.45        10\n",
      "       happy       0.40      0.51      0.45        37\n",
      "    negative       0.45      0.24      0.31        21\n",
      "    surprise       0.47      0.46      0.46        35\n",
      "       toxic       0.31      0.29      0.30        28\n",
      "\n",
      "    accuracy                           0.40       131\n",
      "   macro avg       0.41      0.40      0.39       131\n",
      "weighted avg       0.41      0.40      0.40       131\n",
      "\n",
      "\n",
      "KNN:\n",
      "  Accuracy:  0.6641\n",
      "  F1-Score:  0.6641\n",
      "  Precision: 0.6662\n",
      "  Recall:    0.6641\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fear       0.62      0.50      0.56        10\n",
      "       happy       0.70      0.76      0.73        37\n",
      "    negative       0.45      0.48      0.47        21\n",
      "    surprise       0.79      0.74      0.76        35\n",
      "       toxic       0.64      0.64      0.64        28\n",
      "\n",
      "    accuracy                           0.66       131\n",
      "   macro avg       0.64      0.62      0.63       131\n",
      "weighted avg       0.67      0.66      0.66       131\n",
      "\n",
      "\n",
      "SVM-Linear:\n",
      "  Accuracy:  0.7786\n",
      "  F1-Score:  0.7767\n",
      "  Precision: 0.7780\n",
      "  Recall:    0.7786\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fear       0.80      0.80      0.80        10\n",
      "       happy       0.80      0.89      0.85        37\n",
      "    negative       0.68      0.71      0.70        21\n",
      "    surprise       0.82      0.80      0.81        35\n",
      "       toxic       0.75      0.64      0.69        28\n",
      "\n",
      "    accuracy                           0.78       131\n",
      "   macro avg       0.77      0.77      0.77       131\n",
      "weighted avg       0.78      0.78      0.78       131\n",
      "\n",
      "\n",
      "SVM-RBF:\n",
      "  Accuracy:  0.4962\n",
      "  F1-Score:  0.4406\n",
      "  Precision: 0.4713\n",
      "  Recall:    0.4962\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fear       0.00      0.00      0.00        10\n",
      "       happy       0.41      0.89      0.56        37\n",
      "    negative       0.20      0.05      0.08        21\n",
      "    surprise       0.73      0.63      0.68        35\n",
      "       toxic       0.60      0.32      0.42        28\n",
      "\n",
      "    accuracy                           0.50       131\n",
      "   macro avg       0.39      0.38      0.35       131\n",
      "weighted avg       0.47      0.50      0.44       131\n",
      "\n",
      "\n",
      "Model t·ªët nh·∫•t cho PhoBERT: SVM-Linear (Accuracy: 0.7786)\n",
      "\n",
      "Confusion Matrix cho model t·ªët nh·∫•t (SVM-Linear):\n",
      "[[ 8  2  0  0  0]\n",
      " [ 1 33  2  0  1]\n",
      " [ 1  1 15  1  3]\n",
      " [ 0  4  1 28  2]\n",
      " [ 0  1  4  5 18]]\n",
      "\n",
      "================================================================================\n",
      "‚úÖ HO√ÄN TH√ÄNH T·∫§T C·∫¢ C√ÅC TH·ª¨ NGHI·ªÜM!\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "all_results = {}\n",
    "\n",
    "for encoder_name, encoder in encoders.items():\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"üéØ B·∫ÆT ƒê·∫¶U X·ª¨ L√ù ENCODER: {encoder_name}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    try:\n",
    "        # Hu·∫•n luy·ªán encoder v√† transform d·ªØ li·ªáu\n",
    "        print(f\"\\nüìù ƒêang hu·∫•n luy·ªán {encoder_name}...\")\n",
    "        X_train = encoder.fit_transform(X_train_text)\n",
    "        X_test = encoder.transform(X_test_text)\n",
    "        \n",
    "        print(f\"‚úÖ Ho√†n th√†nh! Shape: Train={X_train.shape}, Test={X_test.shape}\")\n",
    "        \n",
    "        # Ch·∫°y ƒë√°nh gi√° v·ªõi t·∫•t c·∫£ c√°c thu·∫≠t to√°n\n",
    "        results = trainer.run_evaluation(\n",
    "            X_train, X_test,\n",
    "            y_train, y_test,\n",
    "            y_train, y_test,\n",
    "            encoder_name\n",
    "        )\n",
    "        \n",
    "        # L∆∞u k·∫øt qu·∫£\n",
    "        all_results[encoder_name] = results\n",
    "        \n",
    "        # Log c√°c th·ª≠ nghi·ªám\n",
    "        for model_name, metrics in results.items():\n",
    "            logger.log_experiment(encoder_name, model_name, metrics)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå L·ªñI khi x·ª≠ l√Ω {encoder_name}: {str(e)}\")\n",
    "        all_results[encoder_name] = {}\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"‚úÖ HO√ÄN TH√ÄNH T·∫§T C·∫¢ C√ÅC TH·ª¨ NGHI·ªÜM!\")\n",
    "print(f\"{'='*80}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a45a5d60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "T√ìM T·∫ÆT C√ÅC TH·ª¨ NGHI·ªÜM\n",
      "======================================================================\n",
      "\n",
      "[1] BoW + MultinomialNB\n",
      "    Accuracy: 0.7786\n",
      "    F1-Score: 0.7780\n",
      "\n",
      "[2] BoW + LogisticRegressor\n",
      "    Accuracy: 0.8092\n",
      "    F1-Score: 0.8064\n",
      "\n",
      "[3] BoW + RidgeClassifier\n",
      "    Accuracy: 0.7481\n",
      "    F1-Score: 0.7405\n",
      "\n",
      "[4] BoW + DecisionTree\n",
      "    Accuracy: 0.5649\n",
      "    F1-Score: 0.5641\n",
      "\n",
      "[5] BoW + RandomForest\n",
      "    Accuracy: 0.6565\n",
      "    F1-Score: 0.6293\n",
      "\n",
      "[6] BoW + AdaBoost\n",
      "    Accuracy: 0.5496\n",
      "    F1-Score: 0.5350\n",
      "\n",
      "[7] BoW + KNN\n",
      "    Accuracy: 0.5954\n",
      "    F1-Score: 0.5769\n",
      "\n",
      "[8] BoW + SVM-Linear\n",
      "    Accuracy: 0.7863\n",
      "    F1-Score: 0.7822\n",
      "\n",
      "[9] BoW + SVM-RBF\n",
      "    Accuracy: 0.7252\n",
      "    F1-Score: 0.7214\n",
      "\n",
      "[10] TF-IDF + MultinomialNB\n",
      "    Accuracy: 0.7786\n",
      "    F1-Score: 0.7768\n",
      "\n",
      "[11] TF-IDF + LogisticRegressor\n",
      "    Accuracy: 0.7634\n",
      "    F1-Score: 0.7420\n",
      "\n",
      "[12] TF-IDF + RidgeClassifier\n",
      "    Accuracy: 0.7634\n",
      "    F1-Score: 0.7585\n",
      "\n",
      "[13] TF-IDF + DecisionTree\n",
      "    Accuracy: 0.5344\n",
      "    F1-Score: 0.5330\n",
      "\n",
      "[14] TF-IDF + RandomForest\n",
      "    Accuracy: 0.6947\n",
      "    F1-Score: 0.6598\n",
      "\n",
      "[15] TF-IDF + AdaBoost\n",
      "    Accuracy: 0.5420\n",
      "    F1-Score: 0.5075\n",
      "\n",
      "[16] TF-IDF + KNN\n",
      "    Accuracy: 0.6336\n",
      "    F1-Score: 0.6063\n",
      "\n",
      "[17] TF-IDF + SVM-Linear\n",
      "    Accuracy: 0.7710\n",
      "    F1-Score: 0.7667\n",
      "\n",
      "[18] TF-IDF + SVM-RBF\n",
      "    Accuracy: 0.7634\n",
      "    F1-Score: 0.7499\n",
      "\n",
      "[19] TF-IDF-SVD + MultinomialNB\n",
      "    Accuracy: 0.6641\n",
      "    F1-Score: 0.6709\n",
      "\n",
      "[20] TF-IDF-SVD + LogisticRegressor\n",
      "    Accuracy: 0.7863\n",
      "    F1-Score: 0.7688\n",
      "\n",
      "[21] TF-IDF-SVD + RidgeClassifier\n",
      "    Accuracy: 0.7634\n",
      "    F1-Score: 0.7539\n",
      "\n",
      "[22] TF-IDF-SVD + DecisionTree\n",
      "    Accuracy: 0.5038\n",
      "    F1-Score: 0.5032\n",
      "\n",
      "[23] TF-IDF-SVD + RandomForest\n",
      "    Accuracy: 0.6947\n",
      "    F1-Score: 0.6702\n",
      "\n",
      "[24] TF-IDF-SVD + AdaBoost\n",
      "    Accuracy: 0.4962\n",
      "    F1-Score: 0.4635\n",
      "\n",
      "[25] TF-IDF-SVD + KNN\n",
      "    Accuracy: 0.7099\n",
      "    F1-Score: 0.6967\n",
      "\n",
      "[26] TF-IDF-SVD + SVM-Linear\n",
      "    Accuracy: 0.7786\n",
      "    F1-Score: 0.7738\n",
      "\n",
      "[27] TF-IDF-SVD + SVM-RBF\n",
      "    Accuracy: 0.8015\n",
      "    F1-Score: 0.7953\n",
      "\n",
      "[28] Word2Vec + MultinomialNB\n",
      "    Accuracy: 0.2672\n",
      "    F1-Score: 0.2760\n",
      "\n",
      "[29] Word2Vec + LogisticRegressor\n",
      "    Accuracy: 0.3359\n",
      "    F1-Score: 0.2349\n",
      "\n",
      "[30] Word2Vec + RidgeClassifier\n",
      "    Accuracy: 0.3359\n",
      "    F1-Score: 0.2333\n",
      "\n",
      "[31] Word2Vec + DecisionTree\n",
      "    Accuracy: 0.4351\n",
      "    F1-Score: 0.4335\n",
      "\n",
      "[32] Word2Vec + RandomForest\n",
      "    Accuracy: 0.5420\n",
      "    F1-Score: 0.5215\n",
      "\n",
      "[33] Word2Vec + AdaBoost\n",
      "    Accuracy: 0.3740\n",
      "    F1-Score: 0.3581\n",
      "\n",
      "[34] Word2Vec + KNN\n",
      "    Accuracy: 0.3817\n",
      "    F1-Score: 0.3875\n",
      "\n",
      "[35] Word2Vec + SVM-Linear\n",
      "    Accuracy: 0.3359\n",
      "    F1-Score: 0.2349\n",
      "\n",
      "[36] Word2Vec + SVM-RBF\n",
      "    Accuracy: 0.2977\n",
      "    F1-Score: 0.1548\n",
      "\n",
      "[37] FastText + MultinomialNB\n",
      "    Accuracy: 0.3511\n",
      "    F1-Score: 0.3611\n",
      "\n",
      "[38] FastText + LogisticRegressor\n",
      "    Accuracy: 0.3206\n",
      "    F1-Score: 0.1934\n",
      "\n",
      "[39] FastText + RidgeClassifier\n",
      "    Accuracy: 0.3664\n",
      "    F1-Score: 0.2540\n",
      "\n",
      "[40] FastText + DecisionTree\n",
      "    Accuracy: 0.3740\n",
      "    F1-Score: 0.3692\n",
      "\n",
      "[41] FastText + RandomForest\n",
      "    Accuracy: 0.5954\n",
      "    F1-Score: 0.5553\n",
      "\n",
      "[42] FastText + AdaBoost\n",
      "    Accuracy: 0.4198\n",
      "    F1-Score: 0.3967\n",
      "\n",
      "[43] FastText + KNN\n",
      "    Accuracy: 0.5496\n",
      "    F1-Score: 0.5455\n",
      "\n",
      "[44] FastText + SVM-Linear\n",
      "    Accuracy: 0.3817\n",
      "    F1-Score: 0.2695\n",
      "\n",
      "[45] FastText + SVM-RBF\n",
      "    Accuracy: 0.2824\n",
      "    F1-Score: 0.1244\n",
      "\n",
      "[46] CharNgram + MultinomialNB\n",
      "    Accuracy: 0.8626\n",
      "    F1-Score: 0.8642\n",
      "\n",
      "[47] CharNgram + LogisticRegressor\n",
      "    Accuracy: 0.8473\n",
      "    F1-Score: 0.8397\n",
      "\n",
      "[48] CharNgram + RidgeClassifier\n",
      "    Accuracy: 0.8702\n",
      "    F1-Score: 0.8675\n",
      "\n",
      "[49] CharNgram + DecisionTree\n",
      "    Accuracy: 0.5344\n",
      "    F1-Score: 0.5204\n",
      "\n",
      "[50] CharNgram + RandomForest\n",
      "    Accuracy: 0.6947\n",
      "    F1-Score: 0.6783\n",
      "\n",
      "[51] CharNgram + AdaBoost\n",
      "    Accuracy: 0.4198\n",
      "    F1-Score: 0.3720\n",
      "\n",
      "[52] CharNgram + KNN\n",
      "    Accuracy: 0.8550\n",
      "    F1-Score: 0.8487\n",
      "\n",
      "[53] CharNgram + SVM-Linear\n",
      "    Accuracy: 0.9008\n",
      "    F1-Score: 0.9031\n",
      "\n",
      "[54] CharNgram + SVM-RBF\n",
      "    Accuracy: 0.8779\n",
      "    F1-Score: 0.8692\n",
      "\n",
      "[55] PhoBERT + MultinomialNB\n",
      "    Accuracy: 0.3740\n",
      "    F1-Score: 0.3567\n",
      "\n",
      "[56] PhoBERT + LogisticRegressor\n",
      "    Accuracy: 0.7328\n",
      "    F1-Score: 0.7296\n",
      "\n",
      "[57] PhoBERT + RidgeClassifier\n",
      "    Accuracy: 0.7634\n",
      "    F1-Score: 0.7594\n",
      "\n",
      "[58] PhoBERT + DecisionTree\n",
      "    Accuracy: 0.4046\n",
      "    F1-Score: 0.4123\n",
      "\n",
      "[59] PhoBERT + RandomForest\n",
      "    Accuracy: 0.5344\n",
      "    F1-Score: 0.5005\n",
      "\n",
      "[60] PhoBERT + AdaBoost\n",
      "    Accuracy: 0.4046\n",
      "    F1-Score: 0.3983\n",
      "\n",
      "[61] PhoBERT + KNN\n",
      "    Accuracy: 0.6641\n",
      "    F1-Score: 0.6641\n",
      "\n",
      "[62] PhoBERT + SVM-Linear\n",
      "    Accuracy: 0.7786\n",
      "    F1-Score: 0.7767\n",
      "\n",
      "[63] PhoBERT + SVM-RBF\n",
      "    Accuracy: 0.4962\n",
      "    F1-Score: 0.4406\n",
      "\n",
      "======================================================================\n",
      "TH·ª¨ NGHI·ªÜM T·ªêT NH·∫§T\n",
      "======================================================================\n",
      "Feature: CharNgram\n",
      "Model: SVM-Linear\n",
      "Accuracy: 0.9008\n",
      "F1-Score: 0.9031\n",
      "\n",
      "================================================================================\n",
      "üèÜ MODEL T·ªêT NH·∫§T TO√ÄN C·ª§C\n",
      "================================================================================\n",
      "T√™n: CharNgram + SVM-Linear\n",
      "Accuracy: 0.9008\n",
      "Model: LinearSVC\n"
     ]
    }
   ],
   "source": [
    "# In t√≥m t·∫Øt c√°c th·ª≠ nghi·ªám\n",
    "logger.print_summary()\n",
    "\n",
    "# L·∫•y model t·ªët nh·∫•t\n",
    "best_model, best_name, best_score = trainer.get_champion_model()\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"üèÜ MODEL T·ªêT NH·∫§T TO√ÄN C·ª§C\")\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"T√™n: {best_name}\")\n",
    "print(f\"Accuracy: {best_score:.4f}\")\n",
    "print(f\"Model: {type(best_model).__name__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "118c3b7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä B·∫¢NG SO S√ÅNH CHI TI·∫æT:\n",
      "   Encoder             Model  Accuracy  F1-Score  Precision   Recall\n",
      " CharNgram        SVM-Linear  0.900763  0.903089   0.908077 0.900763\n",
      " CharNgram           SVM-RBF  0.877863  0.869246   0.885801 0.877863\n",
      " CharNgram   RidgeClassifier  0.870229  0.867509   0.873286 0.870229\n",
      " CharNgram     MultinomialNB  0.862595  0.864206   0.878546 0.862595\n",
      " CharNgram               KNN  0.854962  0.848682   0.858293 0.854962\n",
      " CharNgram LogisticRegressor  0.847328  0.839658   0.857591 0.847328\n",
      "       BoW LogisticRegressor  0.809160  0.806375   0.808196 0.809160\n",
      "TF-IDF-SVD           SVM-RBF  0.801527  0.795259   0.797054 0.801527\n",
      "       BoW        SVM-Linear  0.786260  0.782231   0.783495 0.786260\n",
      "TF-IDF-SVD LogisticRegressor  0.786260  0.768751   0.802619 0.786260\n",
      "   PhoBERT        SVM-Linear  0.778626  0.776712   0.778032 0.778626\n",
      "    TF-IDF     MultinomialNB  0.778626  0.776835   0.778517 0.778626\n",
      "TF-IDF-SVD        SVM-Linear  0.778626  0.773762   0.776065 0.778626\n",
      "       BoW     MultinomialNB  0.778626  0.778006   0.799045 0.778626\n",
      "    TF-IDF        SVM-Linear  0.770992  0.766746   0.769516 0.770992\n",
      "   PhoBERT   RidgeClassifier  0.763359  0.759434   0.765827 0.763359\n",
      "    TF-IDF LogisticRegressor  0.763359  0.742029   0.748783 0.763359\n",
      "    TF-IDF           SVM-RBF  0.763359  0.749922   0.752911 0.763359\n",
      "TF-IDF-SVD   RidgeClassifier  0.763359  0.753890   0.759427 0.763359\n",
      "    TF-IDF   RidgeClassifier  0.763359  0.758472   0.760567 0.763359\n",
      "       BoW   RidgeClassifier  0.748092  0.740536   0.740662 0.748092\n",
      "   PhoBERT LogisticRegressor  0.732824  0.729647   0.731912 0.732824\n",
      "       BoW           SVM-RBF  0.725191  0.721437   0.738832 0.725191\n",
      "TF-IDF-SVD               KNN  0.709924  0.696662   0.710598 0.709924\n",
      "    TF-IDF      RandomForest  0.694656  0.659828   0.685078 0.694656\n",
      " CharNgram      RandomForest  0.694656  0.678317   0.741160 0.694656\n",
      "TF-IDF-SVD      RandomForest  0.694656  0.670204   0.657985 0.694656\n",
      "TF-IDF-SVD     MultinomialNB  0.664122  0.670879   0.690959 0.664122\n",
      "   PhoBERT               KNN  0.664122  0.664098   0.666192 0.664122\n",
      "       BoW      RandomForest  0.656489  0.629255   0.741219 0.656489\n",
      "    TF-IDF               KNN  0.633588  0.606270   0.648887 0.633588\n",
      "       BoW               KNN  0.595420  0.576926   0.610779 0.595420\n",
      "  FastText      RandomForest  0.595420  0.555314   0.656825 0.595420\n",
      "       BoW      DecisionTree  0.564885  0.564078   0.636896 0.564885\n",
      "       BoW          AdaBoost  0.549618  0.534960   0.566554 0.549618\n",
      "  FastText               KNN  0.549618  0.545544   0.569636 0.549618\n",
      "  Word2Vec      RandomForest  0.541985  0.521453   0.571718 0.541985\n",
      "    TF-IDF          AdaBoost  0.541985  0.507505   0.555328 0.541985\n",
      "    TF-IDF      DecisionTree  0.534351  0.533012   0.598146 0.534351\n",
      "   PhoBERT      RandomForest  0.534351  0.500520   0.542176 0.534351\n",
      " CharNgram      DecisionTree  0.534351  0.520367   0.524647 0.534351\n",
      "TF-IDF-SVD      DecisionTree  0.503817  0.503216   0.514542 0.503817\n",
      "   PhoBERT           SVM-RBF  0.496183  0.440638   0.471303 0.496183\n",
      "TF-IDF-SVD          AdaBoost  0.496183  0.463486   0.452526 0.496183\n",
      "  Word2Vec      DecisionTree  0.435115  0.433493   0.435490 0.435115\n",
      "  FastText          AdaBoost  0.419847  0.396735   0.401976 0.419847\n",
      " CharNgram          AdaBoost  0.419847  0.372022   0.479299 0.419847\n",
      "   PhoBERT          AdaBoost  0.404580  0.398300   0.407969 0.404580\n",
      "   PhoBERT      DecisionTree  0.404580  0.412329   0.424945 0.404580\n",
      "  Word2Vec               KNN  0.381679  0.387468   0.408241 0.381679\n",
      "  FastText        SVM-Linear  0.381679  0.269498   0.243484 0.381679\n",
      "  Word2Vec          AdaBoost  0.374046  0.358107   0.367300 0.374046\n",
      "   PhoBERT     MultinomialNB  0.374046  0.356727   0.447677 0.374046\n",
      "  FastText      DecisionTree  0.374046  0.369155   0.379482 0.374046\n",
      "  FastText   RidgeClassifier  0.366412  0.254035   0.232191 0.366412\n",
      "  FastText     MultinomialNB  0.351145  0.361067   0.426101 0.351145\n",
      "  Word2Vec        SVM-Linear  0.335878  0.234886   0.197367 0.335878\n",
      "  Word2Vec LogisticRegressor  0.335878  0.234886   0.197367 0.335878\n",
      "  Word2Vec   RidgeClassifier  0.335878  0.233265   0.191235 0.335878\n",
      "  FastText LogisticRegressor  0.320611  0.193432   0.275117 0.320611\n",
      "  Word2Vec           SVM-RBF  0.297710  0.154795   0.259761 0.297710\n",
      "  FastText           SVM-RBF  0.282443  0.124409   0.079774 0.282443\n",
      "  Word2Vec     MultinomialNB  0.267176  0.276006   0.393927 0.267176\n",
      "\n",
      "üåü TOP 10 K·∫æT QU·∫¢ T·ªêT NH·∫§T:\n",
      "   Encoder             Model  Accuracy  F1-Score  Precision   Recall\n",
      " CharNgram        SVM-Linear  0.900763  0.903089   0.908077 0.900763\n",
      " CharNgram           SVM-RBF  0.877863  0.869246   0.885801 0.877863\n",
      " CharNgram   RidgeClassifier  0.870229  0.867509   0.873286 0.870229\n",
      " CharNgram     MultinomialNB  0.862595  0.864206   0.878546 0.862595\n",
      " CharNgram               KNN  0.854962  0.848682   0.858293 0.854962\n",
      " CharNgram LogisticRegressor  0.847328  0.839658   0.857591 0.847328\n",
      "       BoW LogisticRegressor  0.809160  0.806375   0.808196 0.809160\n",
      "TF-IDF-SVD           SVM-RBF  0.801527  0.795259   0.797054 0.801527\n",
      "       BoW        SVM-Linear  0.786260  0.782231   0.783495 0.786260\n",
      "TF-IDF-SVD LogisticRegressor  0.786260  0.768751   0.802619 0.786260\n"
     ]
    }
   ],
   "source": [
    "# T·∫°o b·∫£ng so s√°nh\n",
    "comparison_data = []\n",
    "\n",
    "for encoder_name, results in all_results.items():\n",
    "    for model_name, metrics in results.items():\n",
    "        if metrics['accuracy'] > 0:\n",
    "            comparison_data.append({\n",
    "                'Encoder': encoder_name,\n",
    "                'Model': model_name,\n",
    "                'Accuracy': metrics['accuracy'],\n",
    "                'F1-Score': metrics['f1_score'],\n",
    "                'Precision': metrics['precision'],\n",
    "                'Recall': metrics['recall']\n",
    "            })\n",
    "\n",
    "# T·∫°o DataFrame v√† s·∫Øp x·∫øp theo Accuracy\n",
    "df_results = pd.DataFrame(comparison_data)\n",
    "df_results = df_results.sort_values('Accuracy', ascending=False)\n",
    "\n",
    "print(\"\\nüìä B·∫¢NG SO S√ÅNH CHI TI·∫æT:\")\n",
    "print(df_results.to_string(index=False))\n",
    "\n",
    "# Top 10 k·∫øt qu·∫£ t·ªët nh·∫•t\n",
    "print(\"\\nüåü TOP 10 K·∫æT QU·∫¢ T·ªêT NH·∫§T:\")\n",
    "print(df_results.head(10).to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9b3c42cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ƒê√£ l∆∞u k·∫øt qu·∫£ v√†o training_results.pkl\n",
      "‚úÖ ƒê√£ l∆∞u k·∫øt qu·∫£ v√†o training_results.pkl\n",
      "Model t·ªët nh·∫•t: CharNgram + SVM-Linear\n",
      "Encoder t·ªët nh·∫•t: CharNgram\n"
     ]
    }
   ],
   "source": [
    "# Chu·∫©n b·ªã d·ªØ li·ªáu ƒë·ªÉ l∆∞u\n",
    "# L·∫•y encoder t·ªët nh·∫•t ƒë·ªÉ l∆∞u c√πng model\n",
    "best_encoder_name = best_name.split(' + ')[0]\n",
    "best_encoder = encoders.get(best_encoder_name, None)\n",
    "\n",
    "export_data = {\n",
    "    'all_results': all_results,\n",
    "    'best_model': best_model,\n",
    "    'best_encoder': best_encoder,\n",
    "    'best_model_name': best_name,\n",
    "    'best_encoder_name': best_encoder_name,\n",
    "    'best_accuracy': best_score,\n",
    "    'results_dataframe': df_results,\n",
    "    'experiment_log': logger.experiments\n",
    "}\n",
    "\n",
    "# L∆∞u v√†o file pickle\n",
    "save_results_to_pickle(export_data, 'training_results.pkl')\n",
    "\n",
    "print(\"‚úÖ ƒê√£ l∆∞u k·∫øt qu·∫£ v√†o training_results.pkl\")\n",
    "print(f\"Model t·ªët nh·∫•t: {best_name}\")\n",
    "print(f\"Encoder t·ªët nh·∫•t: {best_encoder_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "500aa24b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Ki·ªÉm tra encoder:\n",
      "  - T√™n encoder: CharNgram\n",
      "  - Encoder object: CharNgramEncoder\n",
      "  - Model type: LinearSVC\n",
      "  - Model expects: 768 features\n",
      "  - Encoder output shape: (1, 3632)\n",
      "\n",
      "‚ùå L·ªñI: Shape kh√¥ng kh·ªõp!\n",
      "   Encoder t·∫°o 3632 features\n",
      "   Model c·∫ßn 768 features\n",
      "\n",
      "üí° C√≥ th·ªÉ encoder 'CharNgram' trong dict kh√¥ng ph·∫£i encoder ƒë√£ train model\n"
     ]
    }
   ],
   "source": [
    "# L·∫•y encoder t·ªët nh·∫•t\n",
    "best_encoder_name = best_name.split(' + ')[0]\n",
    "best_encoder_obj = encoders.get(best_encoder_name, None)\n",
    "\n",
    "print(f\"üîç Ki·ªÉm tra encoder:\")\n",
    "print(f\"  - T√™n encoder: {best_encoder_name}\")\n",
    "print(f\"  - Encoder object: {type(best_encoder_obj).__name__ if best_encoder_obj else 'None'}\")\n",
    "print(f\"  - Model type: {type(best_model).__name__}\")\n",
    "print(f\"  - Model expects: {best_model.n_features_in_} features\")\n",
    "\n",
    "if best_encoder_obj is None:\n",
    "    print(f\"\\n‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y encoder {best_encoder_name}\")\n",
    "    print(\"C√°c encoder c√≥ s·∫µn:\", list(encoders.keys()))\n",
    "else:\n",
    "    # Test transform m·ªôt text ƒë·ªÉ xem shape\n",
    "    test_text = \"test sample\"\n",
    "    cleaned_test = DataCleaner.sanitize_content(test_text)\n",
    "    try:\n",
    "        test_features = best_encoder_obj.transform([cleaned_test])\n",
    "        print(f\"  - Encoder output shape: {test_features.shape}\")\n",
    "        \n",
    "        # Ki·ªÉm tra shape c√≥ kh·ªõp kh√¥ng\n",
    "        if test_features.shape[1] != best_model.n_features_in_:\n",
    "            print(f\"\\n‚ùå L·ªñI: Shape kh√¥ng kh·ªõp!\")\n",
    "            print(f\"   Encoder t·∫°o {test_features.shape[1]} features\")\n",
    "            print(f\"   Model c·∫ßn {best_model.n_features_in_} features\")\n",
    "            print(f\"\\nüí° C√≥ th·ªÉ encoder '{best_encoder_name}' trong dict kh√¥ng ph·∫£i encoder ƒë√£ train model\")\n",
    "        else:\n",
    "            print(f\"\\n‚úÖ Shape kh·ªõp! C√≥ th·ªÉ d·ª± ƒëo√°n.\")\n",
    "            \n",
    "            # H√†m d·ª± ƒëo√°n\n",
    "            def predict_text(text):\n",
    "                cleaned = DataCleaner.sanitize_content(text)\n",
    "                features = best_encoder_obj.transform([cleaned])\n",
    "                prediction = best_model.predict(features)\n",
    "                \n",
    "                if hasattr(best_model, 'predict_proba'):\n",
    "                    proba = best_model.predict_proba(features)\n",
    "                    return prediction[0], proba[0]\n",
    "                else:\n",
    "                    return prediction[0], None\n",
    "\n",
    "            # Test\n",
    "            test_samples = [\n",
    "                \"This is a great video, I love it!\",\n",
    "                \"Terrible content, waste of time\",\n",
    "                \"Not bad, could be better\"\n",
    "            ]\n",
    "\n",
    "            print(\"\\nüîÆ D·ª∞ ƒêO√ÅN V·ªöI MODEL T·ªêT NH·∫§T:\")\n",
    "            print(f\"Model: {best_name}\")\n",
    "            print(f\"Encoder: {best_encoder_name}\\n\")\n",
    "\n",
    "            for text in test_samples:\n",
    "                pred, proba = predict_text(text)\n",
    "                print(f\"Text: {text}\")\n",
    "                print(f\"Prediction: {pred}\")\n",
    "                if proba is not None:\n",
    "                    print(f\"Confidence: {max(proba):.4f}\")\n",
    "                print(\"-\" * 50)\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå L·ªói khi test transform: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
